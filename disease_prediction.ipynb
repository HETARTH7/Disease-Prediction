{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7006580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71183d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('Data/Training.csv').dropna(axis = 1)\n",
    "testing= pd.read_csv('Data/Testing.csv').dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a08796e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = training.iloc[:,:-1].values\n",
    "y = training.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test =train_test_split(x, y, test_size = 0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0513e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "pred1=lr.predict(x_test)\n",
    "accuracy1=accuracy_score(y_test, pred1)*100\n",
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba6be8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear', random_state = 0)\n",
    "svm.fit(x_train, y_train)\n",
    "pred2=svm.predict(x_test)\n",
    "accuracy2=accuracy_score(y_test, pred2)*100\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "034ee51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ksv = SVC(kernel = 'rbf', random_state = 0)\n",
    "ksv.fit(x_train, y_train)\n",
    "pred3=ksv.predict(x_test)\n",
    "accuracy3=accuracy_score(y_test, pred3)*100\n",
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97db55a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HETARTH RAVAL\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "knn.fit(x_train, y_train)\n",
    "pred4=knn.predict(x_test)\n",
    "accuracy4=accuracy_score(y_test, pred4)*100\n",
    "accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5b00ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "pred5=nb.predict(x_test)\n",
    "accuracy5=accuracy_score(y_test, pred5)*100\n",
    "accuracy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ef49349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dt.fit(x_train, y_train)\n",
    "pred6=dt.predict(x_test)\n",
    "accuracy6=accuracy_score(y_test, pred6)*100\n",
    "accuracy6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a67245e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "rf.fit(x_train, y_train)\n",
    "pred7=rf.predict(x_test)\n",
    "accuracy7=accuracy_score(y_test, pred7)*100\n",
    "accuracy7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044c7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
